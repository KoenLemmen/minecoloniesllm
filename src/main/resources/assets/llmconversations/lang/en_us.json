{
  "key.categories.llmconversations": "LLM Conversations",
  "key.llmconversations.start_conversation": "Start Conversation",
  "key.llmconversations.cancel_conversation": "Cancel Conversation",

  "llmconversations.message.already_in_conversation": "You are already in a conversation! Type 'goodbye' to end it first.",
  "llmconversations.message.too_far_away": "You are too far away to start a conversation!",
  "llmconversations.message.conversation_started": "Started conversation with %s. Type in chat to talk, or say 'goodbye' to end.",
  "llmconversations.message.not_in_conversation": "You are not in a conversation!",
  "llmconversations.message.citizen_left": "The citizen has left, ending conversation.",
  "llmconversations.message.conversation_ended": "Ended conversation with %s. They're returning to work.",
  "llmconversations.message.handler_lost": "Conversation handler lost, ending conversation.",
  "llmconversations.message.thinking": "*thinking...*",
  "llmconversations.message.initial_greeting": "Hello! How can I help you?",
  "llmconversations.message.no_api_key": "§cError: No OpenRouter API key configured!",
  "llmconversations.message.error_talking": "§cError talking to %s: %s",

  "llmconversations.config.title": "LLM Conversations Configuration",

  "llmconversations.configuration.section.llm_settings": "LLM Settings",
  "llmconversations.configuration.section.idle_conversations": "Idle Conversations",
  "llmconversations.configuration.section.memory": "Memory",
  "llmconversations.configuration.section.conversation_control": "Conversation Control",
  "llmconversations.configuration.section.debug": "Debug",

  "llmconversations.config.api_key": "API Key",
  "llmconversations.config.api_key.tooltip": "Your OpenRouter API key (get from https://openrouter.ai)",

  "llmconversations.config.model": "LLM Model",
  "llmconversations.config.model.tooltip": "The AI model to use for conversations (e.g., anthropic/claude-3-haiku, openai/gpt-4o-mini)",

  "llmconversations.config.system_prompt": "System Prompt",
  "llmconversations.config.system_prompt.tooltip": "System prompt template with placeholders: {name}, {job}, {colony_name}, {player_name}, {happiness}, {saturation}, {skills}",

  "llmconversations.config.max_tokens": "Max Tokens",
  "llmconversations.config.max_tokens.tooltip": "Maximum tokens per response (100-1000)",

  "llmconversations.config.temperature": "Temperature",
  "llmconversations.config.temperature.tooltip": "Response generation temperature (0.0-2.0). Higher = more random, lower = more focused",

  "llmconversations.config.enable_idle_conversations": "Enable Idle Conversations",
  "llmconversations.config.enable_idle_conversations.tooltip": "Enable citizens to randomly start conversations when idle (not implemented yet)",

  "llmconversations.config.idle_conversation_chance": "Idle Conversation Chance",
  "llmconversations.config.idle_conversation_chance.tooltip": "Chance (0.0-1.0) for idle citizen to initiate conversation (not implemented yet)",

  "llmconversations.config.max_history_length": "Max History Length",
  "llmconversations.config.max_history_length.tooltip": "Maximum number of past conversation summaries to remember (0-20)",

  "llmconversations.config.exit_words": "Exit Words",
  "llmconversations.config.exit_words.tooltip": "Words that end a conversation (comma-separated, case-insensitive)",

  "llmconversations.config.debug_mode": "Debug Mode",
  "llmconversations.config.debug_mode.tooltip": "Enable debug logging for LLM conversations",

  "llmconversations.configuration.llm_settings": "LLM Settings",
  "llmconversations.configuration.llm_settings.api_key": "API Key",
  "llmconversations.configuration.llm_settings.model": "LLM Model",
  "llmconversations.configuration.llm_settings.system_prompt": "System Prompt",
  "llmconversations.configuration.llm_settings.max_tokens": "Max Tokens",
  "llmconversations.configuration.llm_settings.temperature": "Temperature",

  "llmconversations.configuration.idle_conversations": "Idle Conversations",
  "llmconversations.configuration.idle_conversations.enable_idle_conversations": "Enable Idle Conversations",
  "llmconversations.configuration.idle_conversations.idle_conversation_chance": "Idle Conversation Chance",

  "llmconversations.configuration.memory": "Memory",
  "llmconversations.configuration.memory.max_history_length": "Max History Length",

  "llmconversations.configuration.conversation_control": "Conversation Control",
  "llmconversations.configuration.conversation_control.exit_words": "Exit Words",

  "llmconversations.configuration.debug": "Debug",
  "llmconversations.configuration.debug.debug_mode": "Debug Mode"
}

